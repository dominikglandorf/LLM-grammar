{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34434f69-8b6b-4858-9317-7d92058dc678",
   "metadata": {},
   "source": [
    "# Exp13: Control Text Generation with a locally running LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8983f68b-3568-4b5a-b093-140877991c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/qb/work/meurers/mpb672/conda_envs/llm2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/scratch_local/mpb672-5191460/tmp/ipykernel_131626/2411790654.py:4: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from accelerate import Accelerator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b090c4e7-ccdc-4725-9b7d-e38787ddf8a9",
   "metadata": {},
   "source": [
    "Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2313cbcd-9f03-43c7-9c27-1a93bae90fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL=\"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271b3c57-ddc2-49b7-ad99-fc397ef40d0d",
   "metadata": {},
   "source": [
    "Load the model and generate three sentences (as indicated by the end of sequence tokens) and print the longest sentence. This re-ranking will be based on the grammar classifiers later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37a89801-6711-434f-bd65-4e2d1aacf143",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:15<00:00,  5.00s/it]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(MODEL, device_map=\"auto\", torch_dtype=torch.float16, cache_dir=\"/mnt/qb/work/meurers/mpb672/cache\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL, cache_dir=\"/mnt/qb/work/meurers/mpb672/cache\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c5ea76-8610-44b8-a3ab-ac381e3d1887",
   "metadata": {},
   "source": [
    "Load the grammar classifiers from the previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a887fe89-1518-4988-ac75-35a7e2729d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskHead(torch.nn.Module):\n",
    "    def __init__(self, bert_hidden_size, num_labels, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = torch.nn.Dropout(dropout_rate)\n",
    "        self.classifier = torch.nn.Linear(bert_hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "class MultiTaskBERT(torch.nn.Module):\n",
    "    def __init__(self, bert, task_heads):\n",
    "        super().__init__()\n",
    "        self.bert = bert\n",
    "        self.task_heads = torch.nn.ModuleList(task_heads)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, task_id):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        task_output = self.task_heads[task_id](pooled_output)\n",
    "        return task_output\n",
    "\n",
    "    def forward_all(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        task_outputs = torch.stack(\n",
    "            [torch.argmax(self.task_heads[task_id](pooled_output), dim=1) for task_id in range(len(self.task_heads))],\n",
    "            dim=1\n",
    "        )\n",
    "        return task_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a70b8f3-eebb-4cab-8c62-58834379fe65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('../dat/egp_merged.json')\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', cache_dir=\"/mnt/qb/work/meurers/mpb672/cache\")\n",
    "backbone_model = BertModel.from_pretrained('bert-base-uncased', cache_dir=\"/mnt/qb/work/meurers/mpb672/cache\")\n",
    "\n",
    "def load_model(level=\"A1\"):    \n",
    "    df_level = df[df['Level'] == level]\n",
    "    num_classifiers = len(df_level)\n",
    "    task_heads = [TaskHead(backbone_model.config.hidden_size, 2) for _ in range(num_classifiers)]\n",
    "    multi_task_model = MultiTaskBERT(copy.deepcopy(backbone_model), task_heads).to(device)\n",
    "    multi_task_model.load_state_dict(torch.load('../models/bert/multi_task_model_state_dict_' + level + '.pth'))\n",
    "    return multi_task_model\n",
    "\n",
    "models = {level: load_model(level) for level in ['A1', 'A2']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2ed5bcd-3fb3-4828-af97-f0dd2b072991",
   "metadata": {},
   "outputs": [],
   "source": [
    "cefr_texts = pd.read_csv(\"../dat/cefr_leveled_texts.csv\")\n",
    "cefr_texts.head()\n",
    "description = {\n",
    "    \"C2\": \"Can understand and interpret critically virtually all forms of the written language including abstract, structurally complex, or highly colloquial literary and non-literary writings. Can understand a wide range of long and complex texts, appreciating subtle distinctions of style and implicit as well as explicit meaning.\",\n",
    "    \"C1\": \"Can understand in detail lengthy, complex texts, whether or not they relate to his/her own area of speciality, provided he/she can reread difficult sections.\",\n",
    "    \"B2\": \"Can read with a large degree of independence, adapting style and speed of reading to different texts and purposes, and using appropriate reference sources selectively. Has a broad active reading vocabulary, but may experience some difficulty with low-frequency idioms.\",\n",
    "    \"B1\": \"Can read straightforward factual texts on subjects related to his/her field and interest with a satisfactory level of comprehension.\",\n",
    "    \"A2\": \"Can understand short, simple texts on familiar matters of a concrete type which consist of high frequency everyday or job-related language. Can understand short, simple texts containing the highest frequency vocabulary, including a proportion of shared international vocabulary items.\",\n",
    "    \"A1\": \"Can understand very short, simple texts a single phrase at a time, picking up familiar names, words and basic phrases and rereading as required.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19c11caf-0e07-4d6b-9982-d35709b1aabf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi!\\nI've been meaning to write for ages and f...</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>﻿It was not so much how hard people found the ...</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Keith recently came back from a trip to Chicag...</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Griffith Observatory is a planetarium, and...</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-LRB- The Hollywood Reporter -RRB- It's offici...</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>Light propagating in the vicinity of astrophys...</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td>Future of dentistry has become one of the most...</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1491</th>\n",
       "      <td>﻿The forests – and suburbs – of Europe are ech...</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1492</th>\n",
       "      <td>Hedge funds are turning bullish on oil once ag...</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493</th>\n",
       "      <td>Without additional heating, radiative cooling ...</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text label\n",
       "0     Hi!\\nI've been meaning to write for ages and f...    B2\n",
       "1     ﻿It was not so much how hard people found the ...    B2\n",
       "2     Keith recently came back from a trip to Chicag...    B2\n",
       "3     The Griffith Observatory is a planetarium, and...    B2\n",
       "4     -LRB- The Hollywood Reporter -RRB- It's offici...    B2\n",
       "...                                                 ...   ...\n",
       "1489  Light propagating in the vicinity of astrophys...    C2\n",
       "1490  Future of dentistry has become one of the most...    C2\n",
       "1491  ﻿The forests – and suburbs – of Europe are ech...    C2\n",
       "1492  Hedge funds are turning bullish on oil once ag...    C2\n",
       "1493  Without additional heating, radiative cooling ...    C2\n",
       "\n",
       "[1494 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cefr_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79069ec7-a50d-4138-adad-9bc3ffcdcead",
   "metadata": {},
   "source": [
    "Generate candidates and rank them using the classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18125dca-faf7-4bbc-84c0-ca322ad4f90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(level_model, candidates, max_len=128):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    \n",
    "    for candidate in candidates:\n",
    "        encoding = bert_tokenizer.encode_plus(\n",
    "            candidate,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        input_ids.append(encoding['input_ids'].squeeze(0))  # Remove the batch dimension\n",
    "        attention_masks.append(encoding['attention_mask'].squeeze(0))\n",
    "    \n",
    "    input_ids = torch.stack(input_ids).to(device)\n",
    "    attention_masks = torch.stack(attention_masks).to(device)\n",
    "    \n",
    "    return level_model.forward_all(input_ids, attention_mask=attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "172e306a-2e54-4caa-89bf-9546594e7c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_candidate(input_ids, max_token_sentence = 64, tok_k=10, eos_chars = [\".\", \"!\", \"?\"]):\n",
    "    generated_tokens = torch.tensor([[]], dtype=torch.int, device=device)\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_token_sentence):\n",
    "            next_token_logits = model(torch.cat([input_ids, generated_tokens], dim=1)).logits\n",
    "            probs = torch.nn.functional.softmax(next_token_logits[:, -1, :], dim=-1)\n",
    "            top_k_probs, top_k_indices = torch.topk(probs, tok_k)\n",
    "            renormalized_top_k_probs = top_k_probs / top_k_probs.sum()\n",
    "            top_k_id = torch.multinomial(renormalized_top_k_probs, num_samples=1).item()\n",
    "            next_token_id = top_k_indices[0, top_k_id]\n",
    "            \n",
    "            next_token = tokenizer.decode(next_token_id)\n",
    "            generated_tokens = torch.cat([generated_tokens, torch.tensor([[next_token_id]]).to(device)], dim=1)\n",
    "            #print(generated_tokens)\n",
    "            if any(eos_char in next_token for eos_char in eos_chars):\n",
    "                break\n",
    "\n",
    "    return tokenizer.decode(generated_tokens[0], skip_special_tokens=True)\n",
    "\n",
    "def write_story(level, story, num_candidates=3, max_len = 512):\n",
    "    while len(story) < max_len:\n",
    "        prompt = f\"<s>[INST] Continue the writing with language on CEFR level {level}. [/INST]\"\n",
    "        inputs = tokenizer(prompt + story, return_tensors=\"pt\").to(device)\n",
    "        candidates = [generate_candidate(inputs.input_ids) for i in range(num_candidates)]\n",
    "        print(candidates)\n",
    "        scores = get_scores(models[level], candidates)\n",
    "        print(torch.mean(scores.float(),dim=1))\n",
    "        story += candidates[torch.argmax(torch.mean(scores.float(),dim=1))] + \" \"\n",
    "    return story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "08c8ff8d-4a7c-4ff3-9ddb-56a3d06910c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_stories = 10\n",
    "num_candidates = 5\n",
    "storyPrompts = cefr_texts.text.apply(lambda text: text[:50].strip().lstrip('\\ufeff')).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b4cc3339-3bad-4e78-9e27-fb16e6a9fc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1\n",
      "['23 p.', '23 p.', '23 p.', '23 p.', '23 p.']\n",
      "tensor([0.1651, 0.1284, 0.1376, 0.1284, 0.1560], device='cuda:0')\n",
      "['m.', 'm.', 'M.', 'm.', 'm.']\n",
      "tensor([0.1009, 0.1101, 0.0917, 0.1101, 0.1193], device='cuda:0')\n",
      "['local time.', 'local time in New York City.', 'local time.', 'local time in New York City -RRB-.', 'local time, New York City.']\n",
      "tensor([0.1651, 0.2018, 0.1468, 0.0367, 0.1651], device='cuda:0')\n",
      "['A big fire has started in a high-rise building in midtown Manhattan.', '\\n\\nA big fire in a high-rise building in Manhattan, New York City.', '-RB- A large fire has started at a skyscraper in the heart of Manhattan.', '\\n-RCB- A fire has started in a high-rise building in Manhattan.', '-RRB- The famous Statue of Liberty has turned green.']\n",
      "tensor([0.1284, 0.1560, 0.0183, 0.0000, 0.0000], device='cuda:0')\n",
      "['\\n\\nFire department on the scene.', '\\n\\nMany people are scared and evacuated their homes.', '\\n\\nFirefighters are fighting the fire on the 15th floor in a tall apartment building in Manhattan.', '\\n\\nMany people are evacuated from the building.', '\\n\\n-RSB- Firemen and emergency services are on the scene, trying to help people who are trapped.']\n",
      "tensor([0.2477, 0.0459, 0.2110, 0.0367, 0.0275], device='cuda:0')\n",
      "['\\n\\nPeople advised to avoid the area.', '\\n\\nPeople urged to stay clear of the area.', '\\n\\nSmoke is coming out of the building.', '\\n\\nMany people evacuated.', '\\n\\n-RSB- Fire?']\n",
      "tensor([0.0550, 0.0367, 0.4587, 0.1009, 0.0183], device='cuda:0')\n",
      "['\\n\\nPlease stay away from the area.', '\\n\\nPeople are running out of the building.', '\\n\\nPeople are asked to avoid the area.', '\\n\\nPeople are running outside.', '\\n\\nPeople are evacuated from the building and surrounding area.']\n",
      "tensor([0.1927, 0.4404, 0.0459, 0.5229, 0.0734], device='cuda:0')\n",
      "['\\n\\nPlease avoid the area.', '\\n\\nHelp!', '\\n\\nAmbulance and police also there to help.', '\\n\\nPolice ask everyone to keep a safe distance.', '\\n\\nHelp needed, please call 911 if you can.']\n",
      "tensor([0.1284, 0.1927, 0.5138, 0.3761, 0.0183], device='cuda:0')\n",
      "['\\n\\nPlease, stay away from the area.', '\\n\\nPlease avoid the area if possible.', '\\n\\nStay tuned for more information.', '\\n\\nStay tuned for more information.', '\\n\\nStay tuned for more information as it comes in.']\n",
      "tensor([0.2385, 0.0550, 0.0092, 0.0183, 0.0000], device='cuda:0')\n",
      "['\\n\\nMore informations coming soon.', '\\n\\nMore information on the news at six.', '\\n\\nWe will keep you updated.', '\\n\\nIf you know someone who lives or works there, please call them to find out if they are safe.', '\\n\\nMore information to follow.']\n",
      "tensor([0.2018, 0.0459, 0.5505, 0.0183, 0.0459], device='cuda:0')\n",
      "['\\n\\n-RSB- Do you speak English?', '\\n\\n-LSB- Hello, this is Lucia speaking for London Speaking Bureau.', '\\n\\n-RSB- Fire in Manhattan, New York City!', '\\n\\n-RSB- Hello and welcome to the news.', '\\n\\n-----------------------------------------\\n\\nHello, welcome to my channel.']\n",
      "tensor([0.0459, 0.1651, 0.0550, 0.0642, 0.0000], device='cuda:0')\n",
      "['\\n\\nWe have some important information to share with you today.', '\\n\\nToday we want to talk about some simple but important things for your everyday life.', '\\n\\nToday, something strange happened in New York City.', '\\n\\nWe have an important announcement to make.', \"\\n\\nToday's topic: Food from around the world.\"]\n",
      "tensor([0.5046, 0.1376, 0.2936, 0.4495, 0.0183], device='cuda:0')\n",
      "['\\n\\nThere is a fire in a big building in New York City.', '\\n\\nA big fire broke out in a high-rise building in Manhattan, New York City.', '\\n\\nAt 6:23 a.', '\\n\\nHave you heard about the fire in a big building in New York City?', '\\n\\nA fire has started in a tall building in New York City.']\n",
      "tensor([0.5229, 0.1835, 0.1651, 0.0550, 0.0826], device='cuda:0')\n",
      "-LSB- Breaking news alert, 6:23 a.m. GMT -LRB- 01:23 p. m. local time in New York City. \n",
      "\n",
      "A big fire in a high-rise building in Manhattan, New York City. \n",
      "\n",
      "Fire department on the scene. \n",
      "\n",
      "Smoke is coming out of the building. \n",
      "\n",
      "People are running outside. \n",
      "\n",
      "Ambulance and police also there to help. \n",
      "\n",
      "Please, stay away from the area. \n",
      "\n",
      "We will keep you updated. \n",
      "\n",
      "-LSB- Hello, this is Lucia speaking for London Speaking Bureau. \n",
      "\n",
      "We have some important information to share with you today. \n",
      "\n",
      "There is a fire in a big building in New York City. \n",
      "['EST circumstances.', 'arest of economic conditions.', 'anner of a strong economy.', 'arest minimum circumstances.', 'anner of a strong economy.']\n",
      "tensor([0.0183, 0.0000, 0.0550, 0.0000, 0.0550], device='cuda:0')\n",
      "['I mean, imagine Italy, with all its beauty and rich history, not paying its bills.', \"I mean, imagine if Italy couldn't pay its debts!\", 'but Spain in 2012, Greece in 2011, and Argentina in 2014 faced a big problem.', 'But when it happens, the repercussions can be immense.', \"But what happens when a country can't pay its debts?\"]\n",
      "tensor([0.0000, 0.0092, 0.1101, 0.0367, 0.0275], device='cuda:0')\n",
      "[\"They couldn't pay back their loans.\", 'They could no longer pay their debts.', \"They couldn't pay their debts.\", \"They couldn't pay their debts, or bills to other countries or organizations.\", \"They couldn't pay their debt.\"]\n",
      "tensor([0.1835, 0.0459, 0.2936, 0.0092, 0.2661], device='cuda:0')\n",
      "['Why?', 'These countries had spent too much money.', 'These countries were in a deep economic crisis.', 'Why?', 'Why?']\n",
      "tensor([0.0642, 0.0183, 0.0092, 0.0550, 0.0642], device='cuda:0')\n",
      "[\"Too many people spent too much money they didn't have!\", 'They had too much money borrowed.', 'They spent too much money than they had.', 'Too much spending, too little income, and debt piled up.', \"\\n\\nGreece's debt crisis began in 2009.\"]\n",
      "tensor([0.0092, 0.0183, 0.0000, 0.0000, 0.0183], device='cuda:0')\n",
      "['Debt is when countries, like individuals, take out loans.', \"\\n\\nWhen countries borrow money, it's like getting a loan.\", 'These countries became ill, like a person who overborrowed and lived beyond their means.', '\\n\\nA default happens when a country cannot pay its debts to the people or institutions that loaned it money.', 'debt is like a big credit card.']\n",
      "tensor([0.0183, 0.0550, 0.0000, 0.0000, 0.2018], device='cuda:0')\n",
      "['\\n\\nGreece, for example, borrowed too much money from other countries and banks.', '\\n\\nGreece, a European country, was a big surprise.', \"\\n\\nWhen these governments couldn't repay, the bond markets stopped lending.\", '\\n\\nWhen Spain, Greece, and Argentina could no longer afford to make their payments, it was a big problem.', \"\\n\\nBut when you miss payments, other countries don't trust you with more money.\"]\n",
      "tensor([0.0000, 0.0550, 0.0000, 0.0000, 0.0183], device='cuda:0')\n",
      "['People were shocked when they heard the news.', 'People were shocked.', \"Many believed Greece's debt problem would not happen.\", 'People thought Europe was rich.', 'People were shocked when it could not pay its bills.']\n",
      "tensor([0.0826, 0.1651, 0.0092, 0.1927, 0.0000], device='cuda:0')\n",
      "['But in 2011, they could not pay their debts and had to ask for help from other European countries and the International Monetary Fund.', 'But Greece had hidden its problems for a long time.', \"But Greece didn't have enough money to pay its bills.\", \"But Greece had spent too much money they didn't have.\", 'But Greece had hidden its real situation.']\n",
      "tensor([0.0092, 0.1101, 0.1376, 0.0734, 0.1376], device='cuda:0')\n",
      "['\\n\\nGreece asked for help.', 'The government spent too much money and borrowed a lot.', '2009 was a tough year, many European countries were struggling.', 'Greece asked for help.', 'The reason?']\n",
      "tensor([0.1193, 0.0275, 0.0367, 0.1284, 0.0092], device='cuda:0')\n",
      "['19 European countries and the International Monetary Fund (IMF) gave them money to pay their debts.', '27 other European countries helped.', '28 other European countries and the European Central Bank gave Greece money.', 'Europe gave them \"bailout.\"', '19 other European countries and the European Central Bank gave Greece loans to pay off some debt.']\n",
      "tensor([0.0459, 0.0826, 0.0183, 0.0734, 0.0183], device='cuda:0')\n",
      "['190 billion euros was the price.', '\\n\\nSpain, another European country, had a housing problem.', '\\n\\nSpain and Argentina also asked for help.', '190 billion euros was given.', '\\n\\nSpain also asked for help.']\n",
      "tensor([0.0092, 0.0092, 0.0642, 0.0183, 0.0275], device='cuda:0')\n",
      "['\\n\\nArgentina\\'s president said, \"We are taking control.', '300 billion euros went to Greece.', '\\n\\nGovernments borrow money for big things like roads, schools, and hospitals.', \"\\n\\nWhen a country can't pay its debts, it's a big problem.\", 'They received aid from other countries.']\n",
      "tensor([0.0092, 0.0092, 0.2844, 0.0183, 0.1743], device='cuda:0')\n",
      "Countries rarely default, at least not under the banner of a strong economy. but Spain in 2012, Greece in 2011, and Argentina in 2014 faced a big problem. They couldn't pay their debts. Why? They had too much money borrowed. debt is like a big credit card. \n",
      "\n",
      "Greece, a European country, was a big surprise. People thought Europe was rich. But Greece didn't have enough money to pay its bills. Greece asked for help. 27 other European countries helped. \n",
      "\n",
      "Spain and Argentina also asked for help. \n",
      "\n",
      "Governments borrow money for big things like roads, schools, and hospitals. \n",
      "A2\n",
      "['23 p.', '13 EST, 07:13 CET-RB-!', '23 p.', '23 p.', '23 p.']\n",
      "tensor([0.4021, 0.4124, 0.3986, 0.4467, 0.4261], device='cuda:0')\n",
      "['m.', 'm.', 'm.', 'm.', 'm.']\n",
      "tensor([0.4880, 0.4330, 0.4605, 0.4639, 0.4708], device='cuda:0')\n",
      "['local time, New York City.', 'local time in New York City -RB-, a big fire is burning in a high-rise building near Times Square.', 'local time for Los Angeles -RRB- The famous Hollywood sign is burning again!', 'local time in New York City.', 'local time in New York City, USA; a massive fire has broken out at a high-rise apartment building in the Financial District.']\n",
      "tensor([0.3849, 0.3574, 0.3127, 0.4124, 0.3402], device='cuda:0')\n",
      "['\\n\\nA massive fire has engulfed a high-rise building in the heart of Manhattan.', '-RB- A terrible accident has occurred near Central Park.', '-RB- A large fire has broken out in a high-rise office building in the heart of Manhattan.', 'A massive fire has erupted at a building in the heart of Manhattan.', '-RB- A massive fire has broken out in an old building near the famous Times Square.']\n",
      "tensor([0.3540, 0.4089, 0.3746, 0.3608, 0.3986], device='cuda:0')\n",
      "['An ambulance, a fire truck, and a police car have rushed to the scene.', '-LSB- Reports indicate that an automobile collided with a pedestrian.', '-LSB- Reports say a bus collided with a car at the busy intersection of Fifth Avenue and Central Park South.', '-LSB- According to eye-witnesses reports, a bus crashed into a tree, causing extensive damage.', '-LSB- What kind of accident?']\n",
      "tensor([0.3402, 0.3540, 0.3780, 0.3540, 0.4777], device='cuda:0')\n",
      "['-LSB- An collision between a bus and a car.', \"-LRB- I'm sorry, I don't have all the details yet, but reports suggest that a bus and a car collided, leading to several injuries.\", '-LRB- A large truck has lost control and crashed into a bus filled with tourists.', '-LRB- A big fire has destroyed several cars and damaged nearby buildings.', '-LRB- A tragic collision between a bus and a car.']\n",
      "tensor([0.4261, 0.3471, 0.4192, 0.4124, 0.4467], device='cuda:0')\n",
      "['-RB- Oh no, how many people were injured or hurt?', '-RB- Oh no!', '-RB- Oh no, how many people are injured or hurt?', '-RB- Oh no, how many people were hurt?', '-RB- Oh no!']\n",
      "tensor([0.4330, 0.4948, 0.4674, 0.4502, 0.4880], device='cuda:0')\n",
      "['How many people were hurt?', 'how many people injured or hurt?', 'How many people are injured or hurt?', 'How many people are injured?', 'How many people were injured or hurt?']\n",
      "tensor([0.5086, 0.4880, 0.4639, 0.5017, 0.4674], device='cuda:0')\n",
      "[\"\\n\\n-LSB- It's still uncertain at this moment, but according to the preliminary reports, there are several injured.\", '\\n\\n-LSB- According to the latest report, several people are injured and the driver of the car has been taken to the hospital with serious injuries.', '\\n-LRB- The exact number is not known at this time, but emergency services are on the scene.', '\\n\\n-LSB- Initial reports indicate that several people were injured in the crash, but the exact number is still unclear.', '\\n\\n-LSB- According to the latest reports from the emergency services, at least ten people have been injured.']\n",
      "tensor([0.4192, 0.3333, 0.3471, 0.2818, 0.3471], device='cuda:0')\n",
      "['\\n\\n-LSB- Where is the accident located?', '\\n\\n-LSB- I see.', '\\n\\n-LSB- Where is the accident location exactly?', '\\n\\n-LSB- Where did this accident happen exactly?', '\\n\\n-LSB- Where exactly did this happen?']\n",
      "tensor([0.4948, 0.4845, 0.5120, 0.4708, 0.4605], device='cuda:0')\n",
      "['\\n\\n-LRB- The accident happened at the intersection of 5th Avenue and Central Park South.', '\\n\\n-LRB- The incident happened at the intersection of Fifth Avenue and Central Park South.', '\\n\\n-LRB- The accident occurred at the intersection of Fifth Avenue and Central Park South, near the famous Plaza Hotel.', '\\n\\n-LRB- The accident happened at the intersection of Fifth Avenue and Central Park South, near the Plaza Hotel.', '\\n\\n-LRB- The incident took place at the intersection of Central Park West and West 59th Street.']\n",
      "tensor([0.4089, 0.4124, 0.3540, 0.3918, 0.3746], device='cuda:0')\n",
      "-LSB- Breaking news alert, 6:23 a.m. GMT -LRB- 01:23 p. m. local time in New York City. -RB- A terrible accident has occurred near Central Park. -LSB- What kind of accident? -LRB- A tragic collision between a bus and a car. -RB- Oh no! How many people were hurt? \n",
      "\n",
      "-LSB- It's still uncertain at this moment, but according to the preliminary reports, there are several injured. \n",
      "\n",
      "-LSB- Where is the accident location exactly? \n",
      "\n",
      "-LRB- The incident happened at the intersection of Fifth Avenue and Central Park South. \n",
      "['arest minimum conditions.', 'arest of economic conditions.', 'anner of a strong economy.', 'arest of economic conditions.', 'arest of circumstances.']\n",
      "tensor([0.4261, 0.4605, 0.4983, 0.4227, 0.4708], device='cuda:0')\n",
      "[\"But when they do, it's big news.\", 'When they do, it can create a ripple effect around the world, shaking the trust in international finance and potentially leading to a global economic crisis.', 'However, sometimes financial problems become too great for even the strongest economies to handle.', 'But what happens when a country faces financial difficulties?', 'But, when it happens, the consequences can be severe.']\n",
      "tensor([0.4261, 0.3746, 0.3986, 0.3986, 0.4124], device='cuda:0')\n",
      "[\"I'm talking about Greece, back in 2010.\", 'A country default is when a government fails to pay its debts to its creditors.', 'Italy, a member of the Eurozone, has the third largest economy in Europe.', 'A country defaulting on its debt means it can no longer pay back the loans it owes to other countries or institutions.', 'Greece, for example, had a big problem a few years ago.']\n",
      "tensor([0.3643, 0.4021, 0.4639, 0.3677, 0.3849], device='cuda:0')\n",
      "['If it defaults, it would be a major financial shock.', 'Yet, this country is in a financial crisis and there are fears it might default on its debt.', 'Yet, it has a significant debt problem.', 'Yet, this once prosperous nation is currently grappling with a mountain of debt.', 'Yet, in 2011, this economic giant came close to collapsing under a huge debt mountain.']\n",
      "tensor([0.4674, 0.4192, 0.3849, 0.4192, 0.4364], device='cuda:0')\n",
      "[\"\\n\\nItaly's public debt is huge: over €2 trillion (2.\", \"\\n\\nItaly's government has a lot of debt.\", \"\\n\\nItaly's debt is very large.\", \"\\n\\nItaly's debt problem began many years ago.\", '\\n\\nItaly has a large public debt, around 131% of its Gross Domestic Product (GDP).']\n",
      "tensor([0.3746, 0.4536, 0.3986, 0.3746, 0.3402], device='cuda:0')\n",
      "['3.', '2.', '3.', '153% of its Gross Domestic Product (GDP).', '2.']\n",
      "tensor([0.4330, 0.4639, 0.4227, 0.4158, 0.4364], device='cuda:0')\n",
      "['3 trillion euros.', '3 trillion euros, or over 130% of its annual economic output.', '3 trillion euros is what they owe.', '3 trillion euros.', '3 trillion euros.']\n",
      "tensor([0.4021, 0.3643, 0.3814, 0.3918, 0.4124], device='cuda:0')\n",
      "[\"That's a lot of zeros.\", \"That's a big number.\", \"That's a lot of money.\", \"That's a lot of money!\", \"That's 132% of their total economy.\"]\n",
      "tensor([0.4330, 0.4089, 0.4021, 0.4089, 0.3333], device='cuda:0')\n",
      "['2.', '2.', '2.', \"It's like having 2.\", '132% of its Gross Domestic Product (GDP).']\n",
      "tensor([0.4777, 0.4742, 0.5017, 0.4192, 0.4330], device='cuda:0')\n",
      "['3 followed by 12 zeros.', '3 thousand billion.', '3 thousand billion euros.', '3 thousand billion.', '3 followed by twelve zeros.']\n",
      "tensor([0.3746, 0.4261, 0.3986, 0.4192, 0.4089], device='cuda:0')\n",
      "['2.', '2.', \"This debt is larger than the country's economic output, which is a problem.\", \"It's like if we each owed twenty-five thousand pounds each.\", \"It's more than all the other countries in Europe combined.\"]\n",
      "tensor([0.4674, 0.4639, 0.3127, 0.3952, 0.3162], device='cuda:0')\n",
      "['3 million million.', '3000.', '3 million million.', '3 million millions!', '3 million millions!']\n",
      "tensor([0.4399, 0.4089, 0.4364, 0.3952, 0.4158], device='cuda:0')\n",
      "['\\n\\nThe Italian government has promised to fix their budget.', \"\\n\\nThe government needs to pay this debt back, but it doesn't have enough money to do so.\", '\\n\\nHow did Italy get so much debt?', \"\\n\\nThe problem is not only the size of the debt, but also the fact that Italy's economy is not growing very fast.\", '\\n\\nThe Italian government has to pay this debt back with interest, which costs a lot of money.']\n",
      "tensor([0.3574, 0.4811, 0.5189, 0.3471, 0.4811], device='cuda:0')\n",
      "[\"\\n\\nWell, it's a complicated story.\", '\\n\\nMany things.', '\\n\\nThere are many reasons.', '\\nSpend, spend, spend.', '\\n\\nThe government spends more than it earns.']\n",
      "tensor([0.4089, 0.4055, 0.4158, 0.4261, 0.3436], device='cuda:0')\n",
      "['\\n\\nThe government has spent on many things, including pensions and healthcare for its large population.', '\\nThey spent on wars, on infrastructure, on social services.', '\\n\\nItaly has spent more money than it earned for many years.', '\\nThey spent on healthcare, education, roads, and other things their people needed.', '\\nThey spent on wars, on building roads and schools, and on helping people with pensions and unemployment.']\n",
      "tensor([0.3299, 0.3574, 0.3918, 0.3814, 0.3196], device='cuda:0')\n",
      "['\\nLike living on a credit card.', '\\nThis is called having a budget deficit.', '\\nBorrowing was easy when interest rates were low.', '\\nLike a credit card, you can use it, but eventually you must pay it back.', '\\nLike living beyond its means on a credit card.']\n",
      "tensor([0.3780, 0.3780, 0.4227, 0.3402, 0.3952], device='cuda:0')\n",
      "Countries rarely default, at least not under the banner of a strong economy. But when they do, it's big news. Italy, a member of the Eurozone, has the third largest economy in Europe. If it defaults, it would be a major financial shock. \n",
      "\n",
      "Italy's government has a lot of debt. 2. 3 trillion euros. That's a lot of zeros. 2. 3 thousand billion. 2. 3 million million. \n",
      "\n",
      "How did Italy get so much debt? \n",
      "Spend, spend, spend. \n",
      "\n",
      "Italy has spent more money than it earned for many years. \n",
      "Borrowing was easy when interest rates were low. \n"
     ]
    }
   ],
   "source": [
    "file_path = \"../dat/controlled_generated_texts_mistral.csv\"\n",
    "if os.path.exists(file_path):\n",
    "    existing_df = pd.read_csv(file_path)\n",
    "else:\n",
    "    existing_df = pd.DataFrame(columns=[\"label\", \"story\", \"text\"])\n",
    "    \n",
    "story_counts = existing_df['label'].value_counts()\n",
    "for level in ['A1', 'A2']: # description.keys()\n",
    "    print(level)\n",
    "    current_count = story_counts.get(level, 0)\n",
    "    stories_to_add = num_stories - current_count\n",
    "    for story in storyPrompts[num_stories-stories_to_add:num_stories+1]:\n",
    "        text = write_story(level, story, num_candidates)\n",
    "        print(text)\n",
    "        new_row = {\"label\": level, \"story\": story, \"text\": text}\n",
    "        pd.DataFrame([new_row]).to_csv(file_path, mode='a', index=False, header=not os.path.exists(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99bf977-3797-415d-b717-77d43656c9c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
