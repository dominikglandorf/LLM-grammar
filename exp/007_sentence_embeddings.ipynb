{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('../dat/egpaugmented_6x100.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [df['augmented_examples'].iloc[0][0]]\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L12-v2')\n",
    "embeddings = model.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "labels = []\n",
    "\n",
    "for _, row in df[5:6].iterrows():\n",
    "    positive_examples = row['augmented_examples']\n",
    "    negative_examples = row['augmented_negative_examples']\n",
    "\n",
    "    for sentence in positive_examples:\n",
    "        sentences.append(sentence)\n",
    "        labels.append(1)  # Label for positive examples\n",
    "\n",
    "    for sentence in negative_examples:\n",
    "        sentences.append(sentence)\n",
    "        labels.append(0)  # Label for negative examples\n",
    "\n",
    "# Generate embeddings\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L12-v2')\n",
    "embeddings = model.encode(sentences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a data loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceDataset(Dataset):\n",
    "    def __init__(self, embeddings, labels):\n",
    "        self.embeddings = embeddings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.embeddings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.embeddings[idx], self.labels[idx]\n",
    "\n",
    "# Creating the dataset and dataloader\n",
    "dataset = SentenceDataset(embeddings, labels)\n",
    "# Total size of the dataset\n",
    "total_size = len(dataset)\n",
    "\n",
    "# Specify the size of the training and validation sets\n",
    "train_size = int(0.8 * total_size)  # 80% for training\n",
    "val_size = total_size - train_size  # Remaining 20% for validation\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders for training and validation\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedforwardNN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(FeedforwardNN, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, 1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden = self.relu(self.fc1(x))\n",
    "        output = self.sigmoid(self.fc2(hidden))\n",
    "        return output\n",
    "\n",
    "# Initialize the network\n",
    "input_dim = embeddings.shape[1]  # Size of the sentence embeddings\n",
    "hidden_dim = 128\n",
    "model = FeedforwardNN(input_dim, hidden_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train the network with the sentence embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.6959, Validation Loss: 0.6941, Accuracy: 0.5000\n",
      "Epoch [2/10], Loss: 0.6912, Validation Loss: 0.6916, Accuracy: 0.5250\n",
      "Epoch [3/10], Loss: 0.6882, Validation Loss: 0.6899, Accuracy: 0.5000\n",
      "Epoch [4/10], Loss: 0.6834, Validation Loss: 0.6868, Accuracy: 0.5000\n",
      "Epoch [5/10], Loss: 0.6810, Validation Loss: 0.6847, Accuracy: 0.5250\n",
      "Epoch [6/10], Loss: 0.6805, Validation Loss: 0.6830, Accuracy: 0.5250\n",
      "Epoch [7/10], Loss: 0.6761, Validation Loss: 0.6795, Accuracy: 0.5250\n",
      "Epoch [8/10], Loss: 0.6688, Validation Loss: 0.6745, Accuracy: 0.5000\n",
      "Epoch [9/10], Loss: 0.6572, Validation Loss: 0.6680, Accuracy: 0.5250\n",
      "Epoch [10/10], Loss: 0.6538, Validation Loss: 0.6644, Accuracy: 0.5000\n",
      "Epoch [11/10], Loss: 0.6432, Validation Loss: 0.6580, Accuracy: 0.5500\n",
      "Epoch [12/10], Loss: 0.6421, Validation Loss: 0.6546, Accuracy: 0.5250\n",
      "Epoch [13/10], Loss: 0.6343, Validation Loss: 0.6487, Accuracy: 0.5250\n",
      "Epoch [14/10], Loss: 0.6238, Validation Loss: 0.6421, Accuracy: 0.5500\n",
      "Epoch [15/10], Loss: 0.6014, Validation Loss: 0.6316, Accuracy: 0.5250\n",
      "Epoch [16/10], Loss: 0.5822, Validation Loss: 0.6227, Accuracy: 0.5250\n",
      "Epoch [17/10], Loss: 0.5724, Validation Loss: 0.6138, Accuracy: 0.5000\n",
      "Epoch [18/10], Loss: 0.5609, Validation Loss: 0.6054, Accuracy: 0.5250\n",
      "Epoch [19/10], Loss: 0.5474, Validation Loss: 0.5972, Accuracy: 0.5750\n",
      "Epoch [20/10], Loss: 0.5232, Validation Loss: 0.5846, Accuracy: 0.5750\n",
      "Epoch [21/10], Loss: 0.4925, Validation Loss: 0.5707, Accuracy: 0.6000\n",
      "Epoch [22/10], Loss: 0.4777, Validation Loss: 0.5619, Accuracy: 0.6000\n",
      "Epoch [23/10], Loss: 0.4695, Validation Loss: 0.5542, Accuracy: 0.6000\n",
      "Epoch [24/10], Loss: 0.4591, Validation Loss: 0.5469, Accuracy: 0.6000\n",
      "Epoch [25/10], Loss: 0.4353, Validation Loss: 0.5337, Accuracy: 0.6000\n",
      "Epoch [26/10], Loss: 0.4130, Validation Loss: 0.5226, Accuracy: 0.6000\n",
      "Epoch [27/10], Loss: 0.3990, Validation Loss: 0.5132, Accuracy: 0.6000\n",
      "Epoch [28/10], Loss: 0.3876, Validation Loss: 0.5055, Accuracy: 0.6000\n",
      "Epoch [29/10], Loss: 0.3777, Validation Loss: 0.4990, Accuracy: 0.6500\n",
      "Epoch [30/10], Loss: 0.3678, Validation Loss: 0.4923, Accuracy: 0.6750\n",
      "Epoch [31/10], Loss: 0.3501, Validation Loss: 0.4834, Accuracy: 0.6750\n",
      "Epoch [32/10], Loss: 0.3390, Validation Loss: 0.4777, Accuracy: 0.6750\n",
      "Epoch [33/10], Loss: 0.3293, Validation Loss: 0.4721, Accuracy: 0.6500\n",
      "Epoch [34/10], Loss: 0.3226, Validation Loss: 0.4669, Accuracy: 0.6500\n",
      "Epoch [35/10], Loss: 0.3246, Validation Loss: 0.4645, Accuracy: 0.6500\n",
      "Epoch [36/10], Loss: 0.3168, Validation Loss: 0.4596, Accuracy: 0.6500\n",
      "Epoch [37/10], Loss: 0.2938, Validation Loss: 0.4503, Accuracy: 0.6750\n",
      "Epoch [38/10], Loss: 0.2830, Validation Loss: 0.4442, Accuracy: 0.7000\n",
      "Epoch [39/10], Loss: 0.2973, Validation Loss: 0.4482, Accuracy: 0.6500\n",
      "Epoch [40/10], Loss: 0.2935, Validation Loss: 0.4447, Accuracy: 0.6500\n",
      "Epoch [41/10], Loss: 0.2826, Validation Loss: 0.4401, Accuracy: 0.7000\n",
      "Epoch [42/10], Loss: 0.2783, Validation Loss: 0.4367, Accuracy: 0.7000\n",
      "Epoch [43/10], Loss: 0.2770, Validation Loss: 0.4357, Accuracy: 0.7000\n",
      "Epoch [44/10], Loss: 0.2777, Validation Loss: 0.4355, Accuracy: 0.7000\n",
      "Epoch [45/10], Loss: 0.2773, Validation Loss: 0.4329, Accuracy: 0.7000\n",
      "Epoch [46/10], Loss: 0.2710, Validation Loss: 0.4293, Accuracy: 0.7250\n",
      "Epoch [47/10], Loss: 0.2702, Validation Loss: 0.4295, Accuracy: 0.7250\n",
      "Epoch [48/10], Loss: 0.2556, Validation Loss: 0.4239, Accuracy: 0.7250\n",
      "Epoch [49/10], Loss: 0.2616, Validation Loss: 0.4264, Accuracy: 0.7250\n",
      "Epoch [50/10], Loss: 0.2705, Validation Loss: 0.4301, Accuracy: 0.7250\n",
      "Epoch [51/10], Loss: 0.2690, Validation Loss: 0.4291, Accuracy: 0.7250\n",
      "Epoch [52/10], Loss: 0.2558, Validation Loss: 0.4227, Accuracy: 0.7250\n",
      "Epoch [53/10], Loss: 0.2643, Validation Loss: 0.4249, Accuracy: 0.7250\n",
      "Epoch [54/10], Loss: 0.2627, Validation Loss: 0.4235, Accuracy: 0.7250\n",
      "Epoch [55/10], Loss: 0.2539, Validation Loss: 0.4208, Accuracy: 0.7250\n",
      "Epoch [56/10], Loss: 0.2618, Validation Loss: 0.4239, Accuracy: 0.7250\n",
      "Epoch [57/10], Loss: 0.2678, Validation Loss: 0.4266, Accuracy: 0.7250\n",
      "Epoch [58/10], Loss: 0.2690, Validation Loss: 0.4268, Accuracy: 0.7250\n",
      "Epoch [59/10], Loss: 0.2539, Validation Loss: 0.4205, Accuracy: 0.7250\n",
      "Epoch [60/10], Loss: 0.2643, Validation Loss: 0.4240, Accuracy: 0.7250\n",
      "Epoch [61/10], Loss: 0.2639, Validation Loss: 0.4243, Accuracy: 0.7250\n",
      "Epoch [62/10], Loss: 0.2577, Validation Loss: 0.4230, Accuracy: 0.7250\n",
      "Epoch [63/10], Loss: 0.2619, Validation Loss: 0.4252, Accuracy: 0.7250\n",
      "Epoch [64/10], Loss: 0.2577, Validation Loss: 0.4229, Accuracy: 0.7250\n",
      "Epoch [65/10], Loss: 0.2574, Validation Loss: 0.4227, Accuracy: 0.7250\n",
      "Epoch [66/10], Loss: 0.2671, Validation Loss: 0.4260, Accuracy: 0.7250\n",
      "Epoch [67/10], Loss: 0.2756, Validation Loss: 0.4299, Accuracy: 0.7250\n",
      "Epoch [68/10], Loss: 0.2548, Validation Loss: 0.4234, Accuracy: 0.7250\n",
      "Epoch [69/10], Loss: 0.2572, Validation Loss: 0.4243, Accuracy: 0.7250\n",
      "Epoch [70/10], Loss: 0.2621, Validation Loss: 0.4270, Accuracy: 0.7250\n",
      "Epoch [71/10], Loss: 0.2550, Validation Loss: 0.4247, Accuracy: 0.7250\n",
      "Epoch [72/10], Loss: 0.2646, Validation Loss: 0.4276, Accuracy: 0.7250\n",
      "Epoch [73/10], Loss: 0.2659, Validation Loss: 0.4285, Accuracy: 0.7250\n",
      "Epoch [74/10], Loss: 0.2599, Validation Loss: 0.4274, Accuracy: 0.7250\n",
      "Epoch [75/10], Loss: 0.2600, Validation Loss: 0.4274, Accuracy: 0.7250\n",
      "Epoch [76/10], Loss: 0.2612, Validation Loss: 0.4279, Accuracy: 0.7250\n",
      "Epoch [77/10], Loss: 0.2631, Validation Loss: 0.4298, Accuracy: 0.7250\n",
      "Epoch [78/10], Loss: 0.2631, Validation Loss: 0.4300, Accuracy: 0.7250\n",
      "Epoch [79/10], Loss: 0.2655, Validation Loss: 0.4324, Accuracy: 0.7250\n",
      "Epoch [80/10], Loss: 0.2692, Validation Loss: 0.4333, Accuracy: 0.7250\n",
      "Epoch [81/10], Loss: 0.2674, Validation Loss: 0.4327, Accuracy: 0.7250\n",
      "Epoch [82/10], Loss: 0.2662, Validation Loss: 0.4320, Accuracy: 0.7250\n",
      "Epoch [83/10], Loss: 0.2647, Validation Loss: 0.4319, Accuracy: 0.7500\n",
      "Epoch [84/10], Loss: 0.2598, Validation Loss: 0.4300, Accuracy: 0.7500\n",
      "Epoch [85/10], Loss: 0.2643, Validation Loss: 0.4340, Accuracy: 0.7500\n",
      "Epoch [86/10], Loss: 0.2708, Validation Loss: 0.4374, Accuracy: 0.7250\n",
      "Epoch [87/10], Loss: 0.2771, Validation Loss: 0.4400, Accuracy: 0.7250\n",
      "Epoch [88/10], Loss: 0.2680, Validation Loss: 0.4368, Accuracy: 0.7500\n",
      "Epoch [89/10], Loss: 0.2637, Validation Loss: 0.4355, Accuracy: 0.7500\n",
      "Epoch [90/10], Loss: 0.2745, Validation Loss: 0.4404, Accuracy: 0.7500\n",
      "Epoch [91/10], Loss: 0.2705, Validation Loss: 0.4387, Accuracy: 0.7500\n",
      "Epoch [92/10], Loss: 0.2680, Validation Loss: 0.4389, Accuracy: 0.7500\n",
      "Epoch [93/10], Loss: 0.2775, Validation Loss: 0.4428, Accuracy: 0.7500\n",
      "Epoch [94/10], Loss: 0.2732, Validation Loss: 0.4415, Accuracy: 0.7500\n",
      "Epoch [95/10], Loss: 0.2657, Validation Loss: 0.4398, Accuracy: 0.7500\n",
      "Epoch [96/10], Loss: 0.2730, Validation Loss: 0.4434, Accuracy: 0.7500\n",
      "Epoch [97/10], Loss: 0.2726, Validation Loss: 0.4438, Accuracy: 0.7500\n",
      "Epoch [98/10], Loss: 0.2796, Validation Loss: 0.4463, Accuracy: 0.7500\n",
      "Epoch [99/10], Loss: 0.2803, Validation Loss: 0.4473, Accuracy: 0.7500\n",
      "Epoch [100/10], Loss: 0.2786, Validation Loss: 0.4470, Accuracy: 0.7500\n"
     ]
    }
   ],
   "source": [
    "# Loss and Optimizer\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(100):  # Number of epochs\n",
    "    model.train()  # Set the model to training mode\n",
    "    for inputs, targets in train_dataloader:\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.squeeze(), targets.float())\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    val_loss = 0\n",
    "    val_steps = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_dataloader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.squeeze(), targets.float())\n",
    "            val_loss += loss.item()\n",
    "            val_steps += 1\n",
    "\n",
    "            # Calculate accuracy\n",
    "            predicted = outputs.round()  # Assuming a binary classification\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted.squeeze() == targets).sum().item()\n",
    "\n",
    "    avg_val_loss = val_loss / val_steps\n",
    "    accuracy = correct / total\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/10], Loss: {loss.item():.4f}, Validation Loss: {avg_val_loss:.4f}, Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-grammar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
