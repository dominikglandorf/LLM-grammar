{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02c05721",
   "metadata": {},
   "source": [
    "# Constrained decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573dbe7a",
   "metadata": {},
   "source": [
    "The goal of this experiment is to reject texts that are too difficult as judged by the sentence classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e636927d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.preview.generative_models import GenerativeModel, Part, HarmCategory, HarmBlockThreshold\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "import config\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "random.seed(config.SEED)\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = config.PATH_TO_GCP_CREDS\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "egp = pd.read_csv('../dat/egponline.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6672a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedforwardNN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(FeedforwardNN, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, 1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden = self.relu(self.fc1(x))\n",
    "        output = self.sigmoid(self.fc2(hidden))\n",
    "        return output\n",
    "\n",
    "embeddings_model = SentenceTransformer('llmrails/ember-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7cdfdaab-381f-45e7-9ead-4fdb28df59c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(text):\n",
    "    doc = nlp(text)\n",
    "    sentences = [token.text.strip() for token in doc.sents]\n",
    "    return list(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ffb9c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4084)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def score(text, level):\n",
    "    sentences = get_sentences(text)\n",
    "    embeddings = embeddings_model.encode(sentences)\n",
    "\n",
    "    total_score = 0\n",
    "    for model_file in os.listdir(\"../models\"):\n",
    "        if not model_file.endswith(\".pth\"): continue\n",
    "        construction = egp[egp['#']==int(model_file[:-4])].iloc[0]\n",
    "        if construction['Level'] == level:\n",
    "            model = torch.load(f\"../models/{model_file}\")\n",
    "            model.eval()\n",
    "            outputs = model(torch.tensor(embeddings, device=device))\n",
    "            total_score += outputs.detach().cpu().mean()\n",
    "        \n",
    "    return total_score\n",
    "\n",
    "text = 'Friends are people who we like, trust, and share common interests with. We sometimes do a lot of things with them.'\n",
    "score(text, 'C2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc9cac0d-f6e4-4d5f-8519-d5341e2af59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cefr_texts = pd.read_csv(\"../dat/cefr_leveled_texts.csv\")\n",
    "cefr_texts.head()\n",
    "description = {\n",
    "    \"C2\": \"Can understand and interpret critically virtually all forms of the written language including abstract, structurally complex, or highly colloquial literary and non-literary writings. Can understand a wide range of long and complex texts, appreciating subtle distinctions of style and implicit as well as explicit meaning.\",\n",
    "    \"C1\": \"Can understand in detail lengthy, complex texts, whether or not they relate to his/her own area of speciality, provided he/she can reread difficult sections.\",\n",
    "    \"B2\": \"Can read with a large degree of independence, adapting style and speed of reading to different texts and purposes, and using appropriate reference sources selectively. Has a broad active reading vocabulary, but may experience some difficulty with low-frequency idioms.\",\n",
    "    \"B1\": \"Can read straightforward factual texts on subjects related to his/her field and interest with a satisfactory level of comprehension.\",\n",
    "    \"A2\": \"Can understand short, simple texts on familiar matters of a concrete type which consist of high frequency everyday or job-related language. Can understand short, simple texts containing the highest frequency vocabulary, including a proportion of shared international vocabulary items.\",\n",
    "    \"A1\": \"Can understand very short, simple texts a single phrase at a time, picking up familiar names, words and basic phrases and rereading as required.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18ef65c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned 4 candidates\n",
      "Accepted 4 candidates\n",
      "Returned 4 candidates\n",
      "Accepted 4 candidates\n",
      "Returned 4 candidates\n",
      "Accepted 4 candidates\n",
      "Returned 4 candidates\n",
      "Accepted 4 candidates\n",
      "Returned 3 candidates\n",
      "Accepted 3 candidates\n",
      "Returned 4 candidates\n",
      "Accepted 4 candidates\n"
     ]
    }
   ],
   "source": [
    "def generate(level, storyPrompt):\n",
    "  model = GenerativeModel(\"gemini-pro\")\n",
    "  print(level)\n",
    "  print(storyPrompt)\n",
    "  \n",
    "  prompt = f\"Write a story using the following prompt on CEFR level {level}Â (Description: {description[level]})\\n\\n{storyPrompt}\"\n",
    "\n",
    "  responses = model.generate_content(\n",
    "    prompt,\n",
    "    safety_settings={\n",
    "        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    },\n",
    "    generation_config={\n",
    "        \"max_output_tokens\": 1024,\n",
    "        \"temperature\": 1,\n",
    "        \"top_p\": 0.9,\n",
    "        \n",
    "    },\n",
    "  stream=True,\n",
    "  )\n",
    "\n",
    "  text = \"\"\n",
    "  for response in responses:\n",
    "    try:\n",
    "      text += response.candidates[0].content.parts[0].text\n",
    "    except Exception as e:\n",
    "      print(response.candidates)\n",
    "      print(e)\n",
    "      #return generate(level, storyPrompt)\n",
    "  return text\n",
    "\n",
    "num_stories = 10\n",
    "num_candidates = 3\n",
    "generated_texts = pd.read_csv(\"../dat/generated_texts.csv\")\n",
    "storyPrompts = generated_texts.story.unique()\n",
    "\n",
    "file_path = \"../dat/controlled_generated_texts.csv\"\n",
    "if os.path.exists(file_path):\n",
    "    existing_df = pd.read_csv(file_path)\n",
    "else:\n",
    "    existing_df = pd.DataFrame(columns=[\"label\", \"story\", \"text\"])\n",
    "    \n",
    "story_counts = existing_df['label'].value_counts()\n",
    "for level in description.keys():\n",
    "    current_count = story_counts.get(level, 0)\n",
    "    stories_to_add = num_stories - current_count\n",
    "\n",
    "    for story in storyPrompts[num_stories-stories_to_add:]:\n",
    "        candidates = [generate(level, story) for _ in range(num_candidates)]\n",
    "        scores = [score(candidate) for candidate in candidates]\n",
    "        print(scores)\n",
    "        text = candidates[scores.index(max(scores))]\n",
    "        new_row = {\"label\": level, \"story\": story, \"text\": text}\n",
    "        pd.DataFrame([new_row]).to_csv(file_path, mode='a', index=False, header=not os.path.exists(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f2fe65f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Friends are people who you like and enjoy spending time with.Friends are people who share common interests and have a mutual bond. Friends are people who care about each other and support each other through thick and thin. Friends are an important part of our lives. Friends are important because they provide emotional support, companionship, and a sense of belonging. Friends are people who you like and enjoy spending time with. Friends are important because they provide emotional support, companionship, and a sense of belonging. '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f71960",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
