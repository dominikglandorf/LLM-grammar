{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp8: Generate text of a certain difficulty level\n",
    "Using prompts that instruct the Gemini Pro model about the requirements for each level, Gemini is asked to generate texts on a certain level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.preview.generative_models import GenerativeModel, Part, HarmCategory, HarmBlockThreshold\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "import config\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import time\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "random.seed(config.SEED)\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = config.PATH_TO_GCP_CREDS\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "egp = pd.read_csv('../dat/egponline.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create some prompts from existing stories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi!\\nI've been meaning to write for ages and f...</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>﻿It was not so much how hard people found the ...</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Keith recently came back from a trip to Chicag...</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Griffith Observatory is a planetarium, and...</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-LRB- The Hollywood Reporter -RRB- It's offici...</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0  Hi!\\nI've been meaning to write for ages and f...    B2\n",
       "1  ﻿It was not so much how hard people found the ...    B2\n",
       "2  Keith recently came back from a trip to Chicag...    B2\n",
       "3  The Griffith Observatory is a planetarium, and...    B2\n",
       "4  -LRB- The Hollywood Reporter -RRB- It's offici...    B2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cefr_texts = pd.read_csv(\"../dat/cefr_leveled_texts.csv\")\n",
    "cefr_texts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who says adult parties have to be boring. More and more adults are reliving their childhoods or crea\n"
     ]
    }
   ],
   "source": [
    "print(cefr_texts.text[20][:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create descriptors and story prompts by using the first 100 characters of each story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = {\n",
    "    \"C2\": \"Can understand and interpret critically virtually all forms of the written language including abstract, structurally complex, or highly colloquial literary and non-literary writings. Can understand a wide range of long and complex texts, appreciating subtle distinctions of style and implicit as well as explicit meaning.\",\n",
    "    \"C1\": \"Can understand in detail lengthy, complex texts, whether or not they relate to his/her own area of speciality, provided he/she can reread difficult sections.\",\n",
    "    \"B2\": \"Can read with a large degree of independence, adapting style and speed of reading to different texts and purposes, and using appropriate reference sources selectively. Has a broad active reading vocabulary, but may experience some difficulty with low-frequency idioms.\",\n",
    "    \"B1\": \"Can read straightforward factual texts on subjects related to his/her field and interest with a satisfactory level of comprehension.\",\n",
    "    \"A2\": \"Can understand short, simple texts on familiar matters of a concrete type which consist of high frequency everyday or job-related language. Can understand short, simple texts containing the highest frequency vocabulary, including a proportion of shared international vocabulary items.\",\n",
    "    \"A1\": \"Can understand very short, simple texts a single phrase at a time, picking up familiar names, words and basic phrases and rereading as required.\"\n",
    "}\n",
    "\n",
    "storyPrompts = [f\"{text[:100]}...\" for text in cefr_texts.text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def generate(level, storyPrompt):\n",
    "  model = GenerativeModel(\"gemini-pro\")\n",
    "  print(level)\n",
    "  print(storyPrompt)\n",
    "  \n",
    "  prompt = f\"Write a story using the following prompt on CEFR level {level} (Description: {description[level]})\\n\\n{storyPrompt}\"\n",
    "  print(prompt)\n",
    "  responses = model.generate_content(\n",
    "    prompt,\n",
    "    safety_settings={ # was necessary due to weird model behavior\n",
    "        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    },\n",
    "    generation_config={\n",
    "        \"max_output_tokens\": 1024,\n",
    "        \"temperature\": 1,\n",
    "        \"top_p\": 0.9,\n",
    "        \n",
    "    },\n",
    "  stream=True,\n",
    "  )\n",
    "\n",
    "  text = \"\"\n",
    "  for response in responses:\n",
    "    try:\n",
    "      text += response.candidates[0].content.parts[0].text\n",
    "    except Exception as e:\n",
    "      print(response.candidates)\n",
    "      print(e)\n",
    "      #return generate(level, storyPrompt)\n",
    "  time.sleep(10)\n",
    "  return text\n",
    "\n",
    "num_stories = 50\n",
    "random.shuffle(storyPrompts)\n",
    "\n",
    "file_path = \"../dat/generated_texts_2.csv\"\n",
    "if os.path.exists(file_path):\n",
    "    existing_df = pd.read_csv(file_path)\n",
    "    existing_stories = list(existing_df.story.unique())\n",
    "    storyPrompts = storyPrompts[slice(0, num_stories-len(existing_stories))] + existing_stories\n",
    "else:\n",
    "    existing_df = pd.DataFrame(columns=[\"label\", \"story\", \"text\"])\n",
    "    \n",
    "\n",
    "story_counts = existing_df['label'].value_counts()\n",
    "for level in description.keys():\n",
    "    current_count = story_counts.get(level, 0)\n",
    "    stories_to_add = num_stories - current_count\n",
    "\n",
    "    for story in storyPrompts[:stories_to_add]:\n",
    "        \n",
    "        text = generate(level, story)\n",
    "        new_row = {\"label\": level, \"story\": story, \"text\": text}\n",
    "        pd.DataFrame([new_row]).to_csv(file_path, mode='a', index=False, header=not os.path.exists(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "George had perpetually exuded an aura of hilarity, captivating those around him with his infectious humor. Our paths crossed serendipitously at the local cinema, where I had eagerly anticipated the release of the latest Spider-Man installment. As fate would have it, George occupied the adjacent seat, and our conversation ignited with an effortless camaraderie that defied the constraints of time.\n",
      "\n",
      "During the ensuing months, George became an integral part of my life. His presence radiated an infectious energy that transformed the mundane into the extraordinary. Whether we embarked on spontaneous road trips, engaged in intellectually stimulating debates, or simply reveled in shared moments of laughter, George possessed an uncanny ability to elevate every experience.\n",
      "\n",
      "One particularly memorable evening, as we strolled through the picturesque streets of our quaint town, George recounted tales of his eccentric family, each anecdote punctuated with his signature wit and charm. His grandmother, a former opera singer, possessed a penchant for belting out impromptu arias while tending to her prize-winning roses. His uncle, a self-proclaimed 'mad scientist,' conducted peculiar experiments in his backyard laboratory, often resulting in comical mishaps that left the entire neighborhood in stitches.\n",
      "\n",
      "Through George's captivating narratives, I gained an intimate glimpse into the tapestry of his remarkable family. Their eccentricities, their triumphs, and their occasional misadventures painted a vibrant portrait of a clan bound together by love, laughter, and an unwavering zest for life.\n",
      "\n",
      "As our friendship deepened, I discovered that beneath George's jovial exterior lay a keen intellect and a compassionate heart. He possessed an insatiable thirst for knowledge, delving into a diverse array of subjects ranging from astrophysics to ancient philosophy. His insights were both profound and thought-provoking, challenging my perspectives and expanding my horizons.\n",
      "\n",
      "Yet, despite his intellectual prowess, George remained remarkably humble and approachable. He had an uncanny ability to connect with people from all walks of life, effortlessly bridging social divides with his infectious humor and genuine empathy. From the elderly shopkeeper to the teenage barista, everyone who encountered George couldn't help but be drawn to his magnetic personality.\n",
      "\n",
      "In the tapestry of my life, George's presence weaved a vibrant thread of joy, laughter, and profound connection. His friendship was a gift that I cherished, a reminder that even in the most ordinary of moments, humor and human connection have the power to transform the mundane into the extraordinary.\n"
     ]
    }
   ],
   "source": [
    "text_df = pd.DataFrame(texts)\n",
    "print(text_df.text[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
